
| distributed init (rank 0): env://, gpu 0
[09:48:31.685485] job dir: /home/sooh/historical-adapters/alpaca_finetuning_v1
[09:48:31.686387] Namespace(accum_iter=1,
adapter_layer=30,
adapter_len=10,
batch_size=4,
blr=0.009,
data_path='/instruction_dataset/',
device='cuda',
dist_backend='nccl',
dist_on_itp=False,
dist_url='env://',
distributed=True,
epochs=10,
gpu=0,
llama_model_path='/data1/data/sooh-data/llama/',
local_rank=8,
log_dir='./output_dir',
lr=None,
max_seq_len=512,
min_lr=0.0,
model='Llama7B_adapter',
num_workers=10,
output_dir='/data1/data/sooh-data/llama/hipe/checkpoint-prompt1/',
pin_mem=True,
rank=0,
resume='',
seed=0,
start_epoch=0,
warmup_epochs=2,
weight_decay=0.02,
world_size=4)
[09:48:32.149541] =================DATA VALIDATION=================
[09:48:32.150052] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fdbe059e9a0>
[09:48:36.626213] /data1/data/sooh-data/llama/7B/consolidated.00.pth
[09:48:38.955053] Model = Transformer(
  (tok_embeddings): Embedding(32000, 4096)
  (adapter_query): Embedding(300, 4096)
  (criterion): CrossEntropyLoss()
  (layers): ModuleList(
    (0-31): 32 x TransformerBlock(
      (attention): Attention(
        (wq): Linear(in_features=4096, out_features=4096, bias=False)
        (wk): Linear(in_features=4096, out_features=4096, bias=False)
        (wv): Linear(in_features=4096, out_features=4096, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=11008, bias=False)
        (w2): Linear(in_features=11008, out_features=4096, bias=False)
        (w3): Linear(in_features=4096, out_features=11008, bias=False)
      )
      (attention_norm): RMSNorm()
      (ffn_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=32000, bias=False)
)
[09:48:38.955384] base lr: 9.00e-03
[09:48:38.955538] actual lr: 5.62e-04
[09:48:38.955684] accumulate grad iterations: 1
[09:48:38.955794] effective batch size: 16
[09:48:38.995095] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005625
    maximize: False
    weight_decay: 0.0
Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005625
    maximize: False
    weight_decay: 0.02
)
[09:48:38.995587] Start training for 10 epochs
[09:48:38.997173] log_dir: ./output_dir
[09:48:42.034437] [09:48:42.034742] [09:48:42.034835] [09:48:42.034920] [09:48:42.035005] [09:48:42.035089] [09:48:42.035172] [09:48:42.035259] [09:48:42.035340] [09:48:42.035422] [09:48:42.035509] [09:48:42.035591] [09:48:42.035674] [09:48:42.035755] [09:48:42.035844]
Exception in thread Thread-4:
Traceback (most recent call last):
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/connection.py", line 509, in Client
    deliver_challenge(c, authkey)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/connection.py", line 740, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
Traceback (most recent call last):
  File "finetuning_hipe_prompt1.py", line 410, in <module>
    main(args)
  File "finetuning_hipe_prompt1.py", line 367, in main
    train_stats = train_one_epoch(
  File "/home/sooh/historical-adapters/alpaca_finetuning_v1/engine_finetuning.py", line 35, in train_one_epoch
    c_loss = model(examples, labels)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sooh/historical-adapters/alpaca_finetuning_v1/llama/model.py", line 246, in forward
    h = layer(h, start_pos, freqs_cis, mask)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sooh/historical-adapters/alpaca_finetuning_v1/llama/model.py", line 198, in forward
    h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask, adapter)
  File "/home/sooh/historical-adapters/alpaca_finetuning_v1/llama/model.py", line 119, in forward
    xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt