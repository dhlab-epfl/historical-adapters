
| distributed init (rank 0): env://, gpu 0
[20:05:03.418164] job dir: /home/sooh/historical-adapters/alpaca_finetuning_v1
[20:05:03.419610] Namespace(accum_iter=1,
adapter_layer=30,
adapter_len=10,
batch_size=4,
blr=0.009,
data_path='/instruction_dataset/',
device='cuda',
dist_backend='nccl',
dist_on_itp=False,
dist_url='env://',
distributed=True,
epochs=30,
gpu=0,
llama_model_path='/data1/data/sooh-data/llama/',
local_rank=-1,
log_dir='./output_dir',
lr=None,
max_seq_len=512,
min_lr=0.0,
model='Llama7B_adapter',
num_workers=10,
output_dir='/data1/data/sooh-data/llama/archiv/checkpoint/',
pin_mem=True,
rank=0,
resume='',
seed=0,
start_epoch=0,
warmup_epochs=2,
weight_decay=0.02,
world_size=8)
[20:05:03.422131] [20:05:03.422326] [20:05:03.422443] [20:05:03.422554] [20:05:03.422676]
Traceback (most recent call last):
  File "finetuning.py", line 336, in <module>
    main(args)
  File "finetuning.py", line 208, in main
    dataset_train = InstructionDataset(model_path = args.llama_model_path, max_words=args.max_seq_len, partition='train')
  File "finetuning.py", line 58, in __init__
    train_dataset = pd.read_csv('data/ArchivalQA/data/ArchivalQA_train.csv')
NameError: name 'pd' is not defined