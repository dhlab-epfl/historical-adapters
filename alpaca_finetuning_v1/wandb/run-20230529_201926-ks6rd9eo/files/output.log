
| distributed init (rank 0): env://, gpu 0
[20:19:35.060255] job dir: /home/sooh/historical-adapters/alpaca_finetuning_v1
[20:19:35.061128] Namespace(accum_iter=1,
adapter_layer=30,
adapter_len=10,
batch_size=4,
blr=0.009,
data_path='/instruction_dataset/',
device='cuda',
dist_backend='nccl',
dist_on_itp=False,
dist_url='env://',
distributed=True,
epochs=30,
gpu=0,
llama_model_path='/data1/data/sooh-data/llama/',
local_rank=-1,
log_dir='./output_dir',
lr=None,
max_seq_len=512,
min_lr=0.0,
model='Llama7B_adapter',
num_workers=10,
output_dir='/data1/data/sooh-data/llama/archiv/checkpoint/',
pin_mem=True,
rank=0,
resume='',
seed=0,
start_epoch=0,
warmup_epochs=2,
weight_decay=0.02,
world_size=8)
[20:20:24.497055] =================DATA VALIDATION=================
[20:20:24.497666] <__main__.InstructionDataset object at 0x7fdcb4612850>
[20:20:24.497783] <__main__.InstructionDataset object at 0x7fdc08f8a220>
[20:20:24.497958] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7fdbfc7d6f70>
[20:21:51.741959] /data1/data/sooh-data/llama/7B/consolidated.00.pth
[20:21:57.172197] Model = Transformer(
  (tok_embeddings): Embedding(32000, 4096)
  (adapter_query): Embedding(300, 4096)
  (criterion): CrossEntropyLoss()
  (layers): ModuleList(
    (0-31): 32 x TransformerBlock(
      (attention): Attention(
        (wq): Linear(in_features=4096, out_features=4096, bias=False)
        (wk): Linear(in_features=4096, out_features=4096, bias=False)
        (wv): Linear(in_features=4096, out_features=4096, bias=False)
        (wo): Linear(in_features=4096, out_features=4096, bias=False)
      )
      (feed_forward): FeedForward(
        (w1): Linear(in_features=4096, out_features=11008, bias=False)
        (w2): Linear(in_features=11008, out_features=4096, bias=False)
        (w3): Linear(in_features=4096, out_features=11008, bias=False)
      )
      (attention_norm): RMSNorm()
      (ffn_norm): RMSNorm()
    )
  )
  (norm): RMSNorm()
  (output): Linear(in_features=4096, out_features=32000, bias=False)
)
[20:21:57.172592] base lr: 9.00e-03
[20:21:57.172737] actual lr: 1.12e-03
[20:21:57.172893] accumulate grad iterations: 1
[20:21:57.173030] effective batch size: 32
[20:21:59.102057] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001125
    maximize: False
    weight_decay: 0.0
Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001125
    maximize: False
    weight_decay: 0.02
)
[20:21:59.102660] Start training for 30 epochs
[20:21:59.104418] log_dir: ./output_dir
[20:22:00.105529] [20:22:00.106162] [20:22:00.106293] [20:22:00.106392] [20:22:00.106494] [20:22:00.106599] [20:22:00.106700] [20:22:00.106792] [20:22:00.106887] [20:22:00.106993]
Traceback (most recent call last):
  File "finetuning.py", line 351, in <module>
    main(args)
  File "finetuning.py", line 308, in main
    train_stats = train_one_epoch(
  File "/home/sooh/historical-adapters/alpaca_finetuning_v1/engine_finetuning.py", line 30, in train_one_epoch
    for data_iter_step, (examples, labels, example_mask) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
  File "/home/sooh/historical-adapters/alpaca_finetuning_v1/util/misc.py", line 144, in log_every
    for obj in iterable:
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
KeyError: Caught KeyError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/sooh/.conda/envs/myenv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "finetuning.py", line 100, in __getitem__
    prompt = PROMPT_DICT['ArchivalQA'].format_map(ann)
KeyError: 'ArchivalQA'